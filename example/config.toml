# prepare（必须）:
#   1、程序运行前，首先需要初始化程序数据表
#   2、配置 reverse 自定义转换规则
#   - 优先级：表字段类型 > 库字段类型 两者都没配置默认采用内置转换规则
# reverse:
#   1、prepare 前提必须阶段
#   2、根据内置表结构转换规则或者手工配置表结构转换规则进行 schema 迁移
# assess:
#   1、用于收集评估 oracle -> mysql/tidb 迁移成本信息，适用于 schema 级别
# check:
#   1、表结构检查(独立于表结构转换，可单独运行，校验规则使用内置规则)
# all:（全量 + 增量模式）
#   1、全量数据迁移
#   2、增量数据迁移
# full: (全量模式)
#   1、全量数据迁移 -> REPLACE INTO
# csv：（全量模式）
#   1、全量数据导出 -> CSV
[app]
# 事务 batch 数
# 用于数据写入 batch 提交事务数
insert-batch-size = 100
# 是否开启更新元数据 meta-schema 库表慢日志，单位毫秒
slowlog-threshold = 1024
# pprof 端口
pprof-port = ":9696"

[reverse]
# 任务表并发
reverse-threads = 128
# 是否直接写下游
# 设置 true 代表表结构转换之后直接往下游执行(不会记录远端 Origin DDL，当建表语句报错报错信息表内会显示)
# 设置 false 代表表结构转换之后写本地文件(本地文件会记录源端 Origin DDL)
direct-write = false
# 当 direct-write 设置 true，参数不生效
# 当 direct-write 设置 false，参数生效，表结构转换写本地文件目录
# 文件输出命名格式: reverse_${source_schema}.sql
ddl-reverse-dir = "/users/marvin/gostore/transferdb/data"
# 忽略 direct-write 参数，关于数据库不兼容性的内容统一以文件形式输出
# 文件输出命名格式: compatible_${source_schema}.sql
ddl-compatible-dir = "/users/marvin/gostore/transferdb/data"

[check]
# 任务表并发
check-threads = 256
# 差异修复文件输出目录
# 文件输出命名格式: check_${source_schema}.sql
check-sql-dir = "/users/marvin/gostore/transferdb/data"

[compare]
chunk-size = 50000
# 检查数据并发数
diff-threads = 128
# 只检查数据行数
# 设置 true 代表只检查数据行数，设置 false 代表使用 checksum 数据对比以及输出对应差异数据
only-check-rows = false
# 断点续检，代表从上次 checkpoint 开始检查
enable-checkpoint = true
# 忽略表结构、collation 以及 character 检查，数据校验是否校验表结构，以上游表结构为准
ignore-struct-check = true
# 差异修复 SQL 文件输出目录, ONLY 用于下游数据库变更修复
fix-sql-dir = "/users/marvin/gostore/transferdb/data"

[csv]
# CSV 文件是否包含表头
header = true
# 字段分隔符，支持一个或多个字符，默认值为 ','
separator = '|#|'
# 行尾定界字符，支持一个或多个字符, 默认值 "\r\n" （回车+换行）
terminator = "|+|\r\n"
# 目标数据字符集
charset = "UTF8MB4"
# 字符串引用定界符，支持一个或多个字符，设置为空表示字符串未加引号
delimiter = '"'
# 使用反斜杠 (\) 来转义导出文件中的特殊字符
escape-backslash = true
# 1、任务行数数，固定动作，一旦确认，不能更改，除非设置 enable-checkpoint = false，重新导出导入
# 2、代表每张表每并发处理多少行数
# 3、代表多少行数据切分一个 csv 文件
# 4、建议是 insert-batch-size 整数倍
rows = 100000
# 数据文件输出目录, 所有表数据输出文件目录，需要磁盘空间充足
# 目录格式：/data/${target_dbname}/${table_name}
output-dir = "/users/marvin/gostore/transferdb/data"
# 用于初始化表任务并发数【写下游 meta 数据库】
task-threads = 128
# 表导出导入并发数，同时处理多少张上游表，可动态变更
table-threads = 8
# 1、单表 SQL 执行并发数，表内并发，表示同时多少并发 SQL 读取上游表数据，可动态变更
# 2、单表 csv 并发写线程数，表示同时多少个 csv 文件同时写，可动态变更
sql-threads = 64
# 关于全量断点恢复
#   - 若想断点恢复，设置 enable-checkpoint = true,首次一旦运行则 chunk-size 数不能调整，
#   - 若不想断点恢复或者重新调整 chunk-size 数，设置 enable-checkpoint = false,重新运行全量任务
#   - 无法断点续传期间，则需要设置 enable-checkpoint = false 重新导入导出
enable-checkpoint = true
# 是否一致性读 ORA
consistent-read = false
# 指定分片 chunk sql 查询 hint
sql-hint = "/*+ PARALLEL(8) */"

[full]
# 表间串行，表内并发
# 任务 chunk 数，固定动作，一旦确认，不能更改，除非设置 enable-checkpoint = false，重新导出导入
# 1、代表每张表每并发处理多少行数
# 2、建议参数值是 insert-batch-size 整数倍，会根据 insert-batch-size 大小切分
chunk-size = 100000
# 用于初始化表任务并发数【写下游 meta 数据库】
task-threads = 128
# 表导出导入并发数，同时处理多少张上游表，可动态变更
table-threads = 4
# 单表 SQL 执行并发数，表示同时多少并发 SQL 读取上游表数据，可动态变更
sql-threads = 32
# 每 sql-threads 线程写下游并发数，可动态变更
apply-threads = 64
# 关于全量断点恢复(ALL/FULL)
#   - 若想断点恢复，设置 enable-checkpoint = true,首次一旦运行则 chunk-size 数不能调整，
#   - 若不想断点恢复或者重新调整 chunk-size 数，设置 enable-checkpoint = false,重新运行全量任务
#   - 无法断点续传期间，则需要设置 enable-checkpoint = false 重新导入导出
enable-checkpoint = true
# 是否一致性读 ORA
consistent-read = false
# 指定分片 chunk sql 查询 hint
sql-hint = "/*+ PARALLEL(8) */"

[all]
# logminer 单次挖掘最长耗时，单位: 秒
logminer-query-timeout   = 300
# 并发筛选 oracle 日志数
filter-threads = 16
# 并发表应用数，同时处理多少张表
apply-threads = 4
# apply-threads 每个表并发处理最大工作对列
worker-queue = 128
# apply-threads 每个表并发处理最大任务分发数
worker-threads = 64

[schema-config]
# 源端 schema
# assess 阶段可设置可不设置，不设置则表示 assess 库内所有 schema，其他阶段必须设置
source-schema = "marvin"
# 目前 only support oracle 作为源端
# 源端迁移任务表（只用于 prepare/reverse/check/all/full 阶段，assess 阶段不适用，assess 只适用于 schema 级别）
# include-table 和 exclude-table 不能同时配置，两者只能配置一个,如果两个都没配置则 Schema 内表全迁移
# include-table 和 exclude-table 支持正则表达式以及通配符（tab_*/tab*）
source-include-table = ["ganyq0"]
source-exclude-table = []
# 目标端 schema
target-schema = "marvin"
# 某些源库源表单独配置 -> 源端表
# 数据校验自定义
#[[schema-config.compare-config]]
# 源端表
#source-table = "marvin"
# 指定 NUMBER 类型字段，必须带索引且是 NUMBER 类型
#index-fields = "id"
# 指定检查数据范围或者查询条件
# range 优先级高于 index-fields
#range = "age > 10 AND age< 20"

# 数据迁移自定义 full/csv
#[[schema-config.migrate-config]]
# 源端表
#source-table = "marvin"
# 基于数据切分策略，获取指定数据迁移表的查询范围
#enable-split = true
# 指定数据迁移表的查询范围
# 注意自定义数据迁移表之后，对应表将只迁移该部分数据
#range = "age > 10 AND age< 20"
# 指定分片 chunk sql 查询 hint
#sql-hint = ""

[oracle]
# 特别说明
# - CDB 架构
# 连接方式 1:
#   1、需要指定 c## 开头的用户
#   2、参数 service-name 需要指定 cdb 级别 service-name
#   3、需要指定 ${schema-name} 所在的 pdb container
# 连接方式 2:
#   1、不指定 c## 开头的用户，指定 pdb 用户
#   2、无需指定 pdb-name，置空
#   3、参数 service-name 指定 pdb servicename
# - NonCDB 架构
# 连接方式:
#   1、指定数据库用户
#   2、无需指定 pdb-name，置空
#   3、参数 service-name 指定对应数据库 servicename
username = "marvin"
password = "marvin"
host = "192.168.0.1"
port = 1521
service-name = "orclpdb1"
# CDB 架构采用 c## 用户连接需指定 ${schema-name} 所在的 pdb container
# NONCDB 架构无须指定，需置空
pdb-name = ""
# oracle instance client dir -> 该配置文件 lib-dir 参数 only windows/macOS 生效, 对于 linux 操作系统，需要手工设置环境变量 LD_LIBRARY_PATH
lib-dir = "/Users/marvin/storehouse/oracle/instantclient_19_8"
# 设置 transferdb 运行环境所在 client 字符集参数，需保持跟 oracle server 一致
# select userenv('language') from dual;
# 常见的 ZHS16GBK 或 AL32UTF8
charset = "AL32UTF8"
# 配置 oracle 连接会话 session 变量
# All/Full/CSV 模式内置 Date/Timestamp/Interval Year/Day 数据类型格式化
# Date 'yyyy-mm-dd hh24:mi:ss'
# Timestamp 'yyyy-mm-dd hh24:mi:ss.ffx', x 根据 timestamp 精度格式化, 如果超过 6, 按精度 6 格式化字符
# Interval Year/Day 数据字符 TO_CHAR 格式化
session-params = []

# 只用于 reverse/check/all/full 阶段，assess 阶段不适用
[mysql]
# 目标端连接串
username = "root"
password = "marvin"
host = "192.168.0.18"
port = 5500
# mysql 链接参数
connect-params = "multiStatements=true&parseTime=True&loc=Local"
# 设置目标端数据库连接字符集，默认字符集 utf8mb4 (tidb 表结构 only utf8mb4, mysql 表结构 utf8mb4、gbk、gb18030 自适应)
# AL32UTF8(UTF8MB4) -> UTF8MB4/GBK/GB18030
# ZHS16GBK(GBK) -> UTF8MB4/GBK/GB18030
# ZHS16GB18030(GB18030) -> UTF8MB4/GBK/GB18030
charset = "UTF8MB4"
# 表后缀可选项 - Only 适用于 Oracle -> TiDB
# TiDB 数据库全局生效（自动读取下游数据参数判定生效与否）：
# tidb_enable_clustered_index = on 全局聚簇索引，table-option 不生效
# tidb_enable_clustered_index = off 全局非聚簇索引，table-option 生效
# tidb_enable_clustered_index = int_only 受配置项 alter-primary-key 控制
# 如果 alter-primary-key = true，则所有主键默认使用非聚簇索引，table-option 生效
# 如果 alter-primary-key = false，除下整数类型的列构成的主键之外，table-option 生效
table-option = "SHARD_ROW_ID_BITS = 4 PRE_SPLIT_REGIONS = 4"

# 用于 prepare 阶段
[meta]
username = "root"
password = "marvin"
host = "192.168.0.19"
port = 3306
# 元数据库【多个 transferdb 同时运行, 元数据库都在同个下游，建议区分 meta-schema 运行】
# CREATE DATABASE IF NOT EXIST transferdb
meta-schema = "transferdb"

[log]
# 日志 level
log-level = "info"
# 日志文件路径
log-file = "./transferdb.log"
# 每个日志文件保存的最大尺寸 单位：M
max-size = 128
# 文件最多保存多少天
max-days = 7
# 日志文件最多保存多少个备份
max-backups = 30